# -*- coding: utf-8 -*-
"""Bhowmik Edition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18TEwIoJFvD4JRuMSOv-oPtcuFqN63dZv
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from google.colab import drive
drive.mount('/content/drive/')

data = pd.read_csv('/content/drive/MyDrive/Data Science/CSVs/sensor_replaced.csv')

data.head()

data.drop(['Unnamed: 0'], axis=1, inplace=True)

data.drop(['timestamp'],axis=1,inplace=True)
data

data.drop(['sensor_00'],axis='columns',inplace=True)
data.drop(['sensor_01'],axis='columns',inplace=True)
data.drop(['sensor_02'],axis='columns',inplace=True)
data.drop(['sensor_03'],axis='columns',inplace=True)
data.drop(['sensor_04'],axis='columns',inplace=True)
data.drop(['sensor_05'],axis='columns',inplace=True)
data.drop(['sensor_06'],axis='columns',inplace=True)
data.drop(['sensor_07'],axis='columns',inplace=True)
data.drop(['sensor_08'],axis='columns',inplace=True)
data.drop(['sensor_09'],axis='columns',inplace=True)
data.drop(['sensor_10'],axis='columns',inplace=True)
data.drop(['sensor_11'],axis='columns',inplace=True)
data.drop(['sensor_12'],axis='columns',inplace=True)
data.drop(['sensor_13'],axis='columns',inplace=True)
data.drop(['sensor_14'],axis='columns',inplace=True)
data.drop(['sensor_15'],axis='columns',inplace=True)
data.drop(['sensor_16'],axis='columns',inplace=True)
data.drop(['sensor_17'],axis='columns',inplace=True)
data.drop(['sensor_18'],axis='columns',inplace=True)
data.drop(['sensor_19'],axis='columns',inplace=True)
data.drop(['sensor_20'],axis='columns',inplace=True)
data.drop(['sensor_21'],axis='columns',inplace=True)
data.drop(['sensor_22'],axis='columns',inplace=True)
data.drop(['sensor_23'],axis='columns',inplace=True)
data.drop(['sensor_24'],axis='columns',inplace=True)
data.drop(['sensor_25'],axis='columns',inplace=True)
data.drop(['sensor_26'],axis='columns',inplace=True)
data.drop(['sensor_27'],axis='columns',inplace=True)
data.drop(['sensor_28'],axis='columns',inplace=True)
data.drop(['sensor_29'],axis='columns',inplace=True)
data.drop(['sensor_30'],axis='columns',inplace=True)
data.drop(['sensor_31'],axis='columns',inplace=True)
data.drop(['sensor_32'],axis='columns',inplace=True)
data.drop(['sensor_33'],axis='columns',inplace=True)
data.drop(['sensor_34'],axis='columns',inplace=True)
data.drop(['sensor_35'],axis='columns',inplace=True)
data.drop(['sensor_36'],axis='columns',inplace=True)
data.drop(['sensor_37'],axis='columns',inplace=True)
data.drop(['sensor_38'],axis='columns',inplace=True)
data.drop(['sensor_39'],axis='columns',inplace=True)
data.drop(['sensor_40'],axis='columns',inplace=True)
data.drop(['sensor_50'],axis='columns',inplace=True)

data.head()

data.machine_status = data.machine_status.map({'NORMAL': 1, 'RECOVERING': 2})

data

data.isnull().sum()

data = data.fillna(data.mean())
data.head()

X = data.drop('machine_status', axis='columns')
y = data['machine_status']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=20)
rf.fit(X_train, y_train)
rf.score(X_test, y_test)

from sklearn import tree
dt = tree.DecisionTreeClassifier()
dt.fit(X_train,y_train)
dt.score(X_test,y_test)

import pickle
Pkl_Pump = "Pickle_RF_Pump.pkl"  

with open(Pkl_Pump, 'wb') as file:  
    pickle.dump(rf, file)

with open(Pkl_Pump, 'rb') as file:  
    Pickle_RF_Pump = pickle.load(file)

Pickle_RF_Pump